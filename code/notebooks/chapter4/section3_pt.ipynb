{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sharing pretrained models (PyTorch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the Transformers, Datasets, and Evaluate libraries to run this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /home/kaushik/projects/Transformers_Hugging_Face/.env/lib/python3.10/site-packages (2.14.4)\n",
      "Requirement already satisfied: evaluate in /home/kaushik/projects/Transformers_Hugging_Face/.env/lib/python3.10/site-packages (0.4.0)\n",
      "Requirement already satisfied: transformers[sentencepiece] in /home/kaushik/projects/Transformers_Hugging_Face/.env/lib/python3.10/site-packages (4.32.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/kaushik/projects/Transformers_Hugging_Face/.env/lib/python3.10/site-packages (from datasets) (1.25.2)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /home/kaushik/projects/Transformers_Hugging_Face/.env/lib/python3.10/site-packages (from datasets) (13.0.0)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /home/kaushik/projects/Transformers_Hugging_Face/.env/lib/python3.10/site-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: pandas in /home/kaushik/projects/Transformers_Hugging_Face/.env/lib/python3.10/site-packages (from datasets) (2.1.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/kaushik/projects/Transformers_Hugging_Face/.env/lib/python3.10/site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/kaushik/projects/Transformers_Hugging_Face/.env/lib/python3.10/site-packages (from datasets) (4.66.1)\n",
      "Requirement already satisfied: xxhash in /home/kaushik/projects/Transformers_Hugging_Face/.env/lib/python3.10/site-packages (from datasets) (3.3.0)\n",
      "Requirement already satisfied: multiprocess in /home/kaushik/projects/Transformers_Hugging_Face/.env/lib/python3.10/site-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /home/kaushik/projects/Transformers_Hugging_Face/.env/lib/python3.10/site-packages (from datasets) (2023.6.0)\n",
      "Requirement already satisfied: aiohttp in /home/kaushik/projects/Transformers_Hugging_Face/.env/lib/python3.10/site-packages (from datasets) (3.8.5)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /home/kaushik/projects/Transformers_Hugging_Face/.env/lib/python3.10/site-packages (from datasets) (0.16.4)\n",
      "Requirement already satisfied: packaging in /home/kaushik/projects/Transformers_Hugging_Face/.env/lib/python3.10/site-packages (from datasets) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/kaushik/projects/Transformers_Hugging_Face/.env/lib/python3.10/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: responses<0.19 in /home/kaushik/projects/Transformers_Hugging_Face/.env/lib/python3.10/site-packages (from evaluate) (0.18.0)\n",
      "Requirement already satisfied: filelock in /home/kaushik/projects/Transformers_Hugging_Face/.env/lib/python3.10/site-packages (from transformers[sentencepiece]) (3.12.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/kaushik/projects/Transformers_Hugging_Face/.env/lib/python3.10/site-packages (from transformers[sentencepiece]) (2023.8.8)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/kaushik/projects/Transformers_Hugging_Face/.env/lib/python3.10/site-packages (from transformers[sentencepiece]) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/kaushik/projects/Transformers_Hugging_Face/.env/lib/python3.10/site-packages (from transformers[sentencepiece]) (0.3.3)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /home/kaushik/projects/Transformers_Hugging_Face/.env/lib/python3.10/site-packages (from transformers[sentencepiece]) (0.1.99)\n",
      "Requirement already satisfied: protobuf in /home/kaushik/projects/Transformers_Hugging_Face/.env/lib/python3.10/site-packages (from transformers[sentencepiece]) (4.24.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/kaushik/projects/Transformers_Hugging_Face/.env/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /home/kaushik/projects/Transformers_Hugging_Face/.env/lib/python3.10/site-packages (from aiohttp->datasets) (3.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/kaushik/projects/Transformers_Hugging_Face/.env/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/kaushik/projects/Transformers_Hugging_Face/.env/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/kaushik/projects/Transformers_Hugging_Face/.env/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/kaushik/projects/Transformers_Hugging_Face/.env/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/kaushik/projects/Transformers_Hugging_Face/.env/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/kaushik/projects/Transformers_Hugging_Face/.env/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.7.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/kaushik/projects/Transformers_Hugging_Face/.env/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/kaushik/projects/Transformers_Hugging_Face/.env/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/kaushik/projects/Transformers_Hugging_Face/.env/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/kaushik/projects/Transformers_Hugging_Face/.env/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/kaushik/projects/Transformers_Hugging_Face/.env/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/kaushik/projects/Transformers_Hugging_Face/.env/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/kaushik/projects/Transformers_Hugging_Face/.env/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install datasets evaluate transformers[sentencepiece]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "apt install requires user with root privilege. Else executing the command by prepending sudo fails to take password input in Ipython notebook.\n",
    "\n",
    "Solution #1: Run sudo command using os library by passing password as argument. This is not recommended due to security risk.\n",
    "\n",
    "Solution #2: Edit sudoers file to allow non-root users with sudo permission for specific commands.\n",
    "\n",
    "Simpler solution: If you are running locally, better run the install command in shell script and then execute this notebook by commenting out the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mE: \u001b[0mCould not open lock file /var/lib/dpkg/lock-frontend - open (13: Permission denied)\u001b[0m\n",
      "\u001b[1;31mE: \u001b[0mUnable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root?\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!apt install git-lfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to setup git, adapt your email and name in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git config user.email \"you@example.com\"\n",
    "!git config user.name \"Your Name\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will also need to be logged in to the Hugging Face Hub. Execute the following and enter your credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c36cca5fb6448939bec031ab44ed755",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    \"bert-finetuned-mrpc\",\n",
    "    save_strategy=\"epoch\",\n",
    "    push_to_hub=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Access the Model Hub via push_to_hub() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at camembert-base were not used when initializing CamembertForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing CamembertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CamembertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "\n",
    "checkpoint = \"camembert-base\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = AutoModelForMaskedLM.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"dummy-camembert-base-model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0bbbdc88c5c48cbbb971014f3190f8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/443M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/kaushikacharya/dummy-camembert-base-model/commit/d833f8058183f56bc24490d29457ab72d2bacb41', commit_message='Upload CamembertForMaskedLM', commit_description='', oid='d833f8058183f56bc24490d29457ab72d2bacb41', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38f895da73c84e549b9c5b59cfb90135",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/811k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/kaushikacharya/dummy-camembert-base-model/commit/6d48ec0d5f77e3516d59107c5d54143790beb451', commit_message='Upload tokenizer', commit_description='', oid='6d48ec0d5f77e3516d59107c5d54143790beb451', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.push_to_hub(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.push_to_hub(\"dummy-model\", organization=\"huggingface\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.push_to_hub(\"dummy-model\", organization=\"huggingface\", use_auth_token=\"<TOKEN>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the huggingface_hub Python library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import (\n",
    "    # User management\n",
    "    login,\n",
    "    logout,\n",
    "    whoami,\n",
    "\n",
    "    # Repository creation and management\n",
    "    create_repo,\n",
    "    delete_repo,\n",
    "    update_repo_visibility,\n",
    "\n",
    "    # And some methods to retrieve/change information about the content\n",
    "    list_models,\n",
    "    list_datasets,\n",
    "    list_metrics,\n",
    "    list_repo_files,\n",
    "    upload_file,\n",
    "    delete_file,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"test-dummy-model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models: ['kaushikacharya/dummy-model', 'kaushikacharya/dummy-camembert-base-model']\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import create_repo, delete_repo, list_models, RepoUrl\n",
    "\n",
    "author = \"kaushikacharya\"\n",
    "models = [x.modelId for x in list_models(author=author)]\n",
    "print(f\"Models: {models}\")\n",
    "\n",
    "# Delete the model if already existing\n",
    "if f\"{author}/{model_name}\" in models:\n",
    "    delete_repo(repo_id=model_name)\n",
    "\n",
    "repo_url = create_repo(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import create_repo\n",
    "\n",
    "create_repo(\"dummy-model\", organization=\"huggingface\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "upload_file approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/kaushik/projects/Transformers_Hugging_Face/code/notebooks/chapter4'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check which one is the current directory\n",
    "import os\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dummy config json file\n",
    "import json\n",
    "\n",
    "config_dict = {\n",
    "    \"_name_or_path\": model_name,\n",
    "    \"architectures\": [\n",
    "        \"CamembertForMaskedLM\"\n",
    "    ],\n",
    "    \"vocab_size\": 32005\n",
    "}\n",
    "\n",
    "with open(\"config.json\", \"w\") as fp:\n",
    "    json.dump(config_dict, fp=fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload the above created config.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/kaushikacharya/test-dummy-model/blob/main/config.json'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import upload_file\n",
    "\n",
    "upload_file(\n",
    "    path_or_fileobj=\"config.json\",\n",
    "    path_in_repo=\"config.json\",\n",
    "    repo_id=f\"{author}/{model_name}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repository class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning https://huggingface.co/kaushikacharya/test-dummy-model into local empty directory.\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import Repository\n",
    "\n",
    "repo = Repository(local_dir=f\"../../{model_name}\",\n",
    "                  clone_from=f\"{author}/{model_name}\"\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo.git_pull()\n",
    "repo.git_add()\n",
    "repo.git_commit()\n",
    "repo.git_push()\n",
    "repo.git_tag()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo.git_pull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"<path_to_dummy_folder>\")\n",
    "tokenizer.save_pretrained(\"<path_to_dummy_folder>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo.git_add()\n",
    "repo.git_commit(\"Add model and tokenizer files\")\n",
    "repo.git_push()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForMaskedLM, AutoTokenizer\n",
    "\n",
    "checkpoint = \"camembert-base\"\n",
    "\n",
    "model = AutoModelForMaskedLM.from_pretrained(checkpoint)\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "# Do whatever with the model, train it, fine-tune it...\n",
    "\n",
    "model.save_pretrained(\"<path_to_dummy_folder>\")\n",
    "tokenizer.save_pretrained(\"<path_to_dummy_folder>\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Sharing pretrained models (PyTorch)",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
